---
id: 75.08
tags: [type/tool, status/evergreen, context/dev-tools]
---

# oha

## Overview
**oha** is a fast, Rust-based HTTP load generator designed for stress testing and benchmarking web APIs. It supports **rate-limiting** (target QPS), **latency correction** (avoids Coordinated Omission Problem), and outputs structured JSON for automated analysis.

ðŸ”— **Repo**: [github.com/hatoo/oha](https://github.com/hatoo/oha)

## Key Features
- **Written in Rust** â€” High performance, low overhead on the load-generator side
- **Rate-limited mode** (`-q`) â€” Send at a specific QPS target instead of max-blast
- **Latency correction** (`--latency-correction`) â€” Accounts for queuing delay, avoids Coordinated Omission
- **JSON output** (`--output-format json`) â€” Machine-readable results for pipeline integration
- **TUI dashboard** â€” Real-time progress display (disable with `--no-tui` for scripting)
- **HTTP/2 support** â€” Test modern endpoints

## Installation

| Platform | Command |
|---|---|
| macOS | `brew install oha` |
| Windows | `winget install hatoo.oha` |
| Linux | `cargo install oha` |

## Common Usage

```bash
# Basic: 10s test, 100 concurrent connections
oha -z 10s -c 100 http://localhost:8000/endpoint

# Rate-limited: 5000 QPS target with latency correction
oha -z 20s -c 500 -q 5000 --latency-correction http://localhost:8000/endpoint

# JSON output for scripting (no TUI)
oha -z 10s -c 100 -q 1000 --no-tui --output-format json http://localhost:8000/endpoint > result.json
```

## Key Flags

| Flag | Purpose |
|---|---|
| `-z <duration>` | Test duration (e.g., `10s`, `1m`) |
| `-n <count>` | Total number of requests |
| `-c <num>` | Concurrent connections |
| `-q <qps>` | Rate limit (requests per second per worker) |
| `--latency-correction` | Fix Coordinated Omission Problem |
| `--no-tui` | Disable interactive dashboard |
| `--output-format json` | Structured JSON output |

## JSON Output Structure

Key fields in the JSON output:

| Path | Metric |
|---|---|
| `summary.requestsPerSec` | Actual achieved RPS |
| `summary.successRate` | Fraction of 2xx responses |
| `summary.fastest` / `slowest` | Min/max latency (seconds) |
| `latencyPercentiles.p50` | Median latency |
| `latencyPercentiles.p95` | 95th percentile latency |
| `latencyPercentiles.p99` | 99th percentile latency |
| `rps.mean` / `rps.stddev` | RPS statistics |

## oha vs Alternatives

| Tool | Language | Rate Limiting | Latency Correction | JSON Output |
|---|---|---|---|---|
| **oha** | Rust | âœ… | âœ… | âœ… |
| **wrk** | C | âŒ (Lua script) | âŒ | âŒ |
| **hey** | Go | âœ… (`-q`) | âŒ | âŒ (CSV) |
| **ab** | C | âŒ | âŒ | âŒ |
| **k6** | Go/JS | âœ… | âœ… | âœ… |
| **locust** | Python | âœ… | âœ… | âœ… |

> [!TIP] Why oha over wrk/hey
> oha's `--latency-correction` flag is critical for finding the real breaking point (hockey-stick latency curve). Without it, tools report optimistic latency by not accounting for queued requests.

> [!INFO] Coordinated Omission Problem
> When a server slows down, most load generators also slow their request rate, missing the true latency impact. Latency correction simulates that requests *should* have been sent on time, producing realistic percentile measurements.

## Related Concepts
- [[75_Dev_Tools_MOC]] - Parent category
- [[75.06 perf-api-framework]] - Uses oha as the load generator
