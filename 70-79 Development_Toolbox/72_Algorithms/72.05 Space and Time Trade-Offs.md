---
id: 72.05
tags: [type/concept, status/evergreen, context/dev-tools]
---

# Space and Time Trade-Offs

## Overview

**Space-Time Trade-Off** is an algorithm design principle where extra memory is used to reduce computation time, or vice versa. The core idea: **precompute and store** results to avoid repeated calculations.

## Key Concepts

| Strategy | Space Cost | Time Benefit | Example |
|----------|------------|--------------|---------|
| **Input Enhancement** | Preprocess input into auxiliary structure | Faster queries/operations | Hash tables, sorted indices |
| **Prestructuring** | Build data structure before queries | $O(1)$ or $O(\log n)$ lookups | B-trees, tries, suffix arrays |
| **Caching/Memoization** | Store computed results | Avoid recomputation | DP tables, LRU cache |

> [!INFO] The Trade-Off Equation
> If you have $Q$ queries on data of size $n$:
> - Without preprocessing: $O(Q \cdot n)$
> - With $O(n)$ preprocessing: $O(n + Q \cdot \log n)$ or $O(n + Q)$

## Techniques

### Hashing

Trade $O(n)$ space for $O(1)$ average-case operations:

| Operation | Array | Sorted Array | Hash Table |
|-----------|-------|--------------|------------|
| Search | $O(n)$ | $O(\log n)$ | $O(1)$ avg |
| Insert | $O(1)$ | $O(n)$ | $O(1)$ avg |
| Delete | $O(n)$ | $O(n)$ | $O(1)$ avg |

> [!WARNING] Hash Collisions
> Worst-case $O(n)$ if poor hash function. Use consistent hashing for distributed systems.

### B-Trees (Database Indexing)

Trade disk space for I/O efficiency:
- **Branching factor** $m$: each node has up to $m$ children
- **Height**: $O(\log_m n)$ → fewer disk reads
- Used in: PostgreSQL, MySQL, file systems

### Counting-Based Methods

**Counting Sort**: Trade $O(k)$ space for $O(n+k)$ time
- Works when range $k$ is known and small
- Stable sort without comparisons

**String Matching (Horspool/Boyer-Moore)**:
- Precompute shift table: $O(|\Sigma|)$ space
- Skip characters: sublinear average time

### Precomputation Examples

| Problem | Precompute | Query Time | Space |
|---------|------------|------------|-------|
| Range sum queries | Prefix sums | $O(1)$ | $O(n)$ |
| LCA in trees | Sparse table | $O(1)$ | $O(n \log n)$ |
| Pattern matching | Failure function (KMP) | $O(n+m)$ | $O(m)$ |
| Substring search | Suffix array | $O(m \log n)$ | $O(n)$ |

## When to Use More Space

- ✅ **Multiple queries** on same data
- ✅ **Real-time constraints** where latency matters
- ✅ **Read-heavy workloads** (caching pays off)
- ❌ **Memory-constrained** environments (embedded, edge)
- ❌ **One-time operations** (preprocessing overhead not amortized)

## Practical Use Cases

- **Database indices**: B-tree, hash index, bloom filters
- **Web caching**: CDN, Redis, browser cache
- **ML inference**: Precomputed embeddings, quantization tables
- **Compilers**: Symbol tables, memoized parsing

## Related Concepts

- [[72_Algorithms_MOC]]
- [[72.15 Hash Table Techniques]]
- [[72.06 Dynamic Programming]]
- [[72.04 Transform-and-Conquer]]
