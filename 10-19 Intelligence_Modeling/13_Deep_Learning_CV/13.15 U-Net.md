---
id: 13.15
tags: [type/concept, status/evergreen, context/dl]
---

# U-Net

## Overview
**U-Net** (Ronneberger et al., 2015) is an encoder-decoder CNN architecture designed for **biomedical image segmentation**. Its defining feature is **skip connections** that directly link encoder feature maps to the corresponding decoder layers, preserving fine-grained spatial detail that would otherwise be lost during downsampling.

> [!INFO] Why "U-Net"?
> The architecture forms a symmetric **U-shape**: the left side contracts (encoder), the right side expands (decoder), and skip connections bridge them horizontally at each resolution level.

## Architecture

```
Input Image (572×572)
        │
  ┌─────▼─────┐
  │  Conv 3×3 │  ← Encoder block 1 (64ch)
  │  Conv 3×3 │
  │  MaxPool  │──────────────────────────────────────────────┐ skip
  │           │                                              │
  │  Conv 3×3 │  ← Encoder block 2 (128ch)                  │
  │  MaxPool  │──────────────────────────────────────┐ skip  │
  │           │                                      │       │
  │  Conv 3×3 │  ← Encoder block 3 (256ch)           │       │
  │  MaxPool  │──────────────────────────────┐ skip  │       │
  │           │                              │       │       │
  │  Conv 3×3 │  ← Encoder block 4 (512ch)  │       │       │
  │  MaxPool  │──────────────────────┐ skip  │       │       │
  │           │                      │       │       │       │
  │  Bottleneck (1024ch)             │       │       │       │
  │           │                      │       │       │       │
  │  UpConv   │◄─────────────────────┘       │       │       │
  │  Conv 3×3 │  ← Decoder block 4 (512ch)   │       │       │
  │  UpConv   │◄─────────────────────────────┘       │       │
  │  Conv 3×3 │  ← Decoder block 3 (256ch)           │       │
  │  UpConv   │◄─────────────────────────────────────┘       │
  │  Conv 3×3 │  ← Decoder block 2 (128ch)                   │
  │  UpConv   │◄──────────────────────────────────────────────┘
  │  Conv 3×3 │  ← Decoder block 1 (64ch)
  └─────┬─────┘
  Conv 1×1 (num_classes)
        │
  Segmentation Map
```

## Key Components

| Component | Role |
|---|---|
| **Encoder (contracting path)** | Two 3×3 convs + ReLU, then 2×2 max pool. Captures semantic context at decreasing spatial resolution. |
| **Bottleneck** | Deepest layer — highest channel count (1024), smallest spatial size. |
| **Decoder (expanding path)** | 2×2 transposed conv (upsampling) + concatenate skip + two 3×3 convs. Restores spatial resolution. |
| **Skip connections** | Concatenate encoder feature maps to decoder at each resolution. Preserves edges, textures, fine structure. |
| **1×1 final conv** | Maps features to per-pixel class logits. |

## Skip Connections — Why They Matter

Without skip connections the decoder must reconstruct spatial detail from a compressed bottleneck alone:

```
Without skip:  [bottleneck] → expand → coarse mask (blurry edges)
With skip:     [bottleneck] → expand → concat(encoder_features) → precise mask
```

- **High-resolution encoder maps** retain exact positions of edges and thin structures
- **Low-resolution bottleneck** carries semantic context (what is where)
- Concatenation forces the decoder to use both

## Variants

| Variant | Key Change | Use Case |
|---|---|---|
| **U-Net** (original) | Sigmoid output, overlap-tile strategy for large images | Binary biomedical segmentation |
| **U-Net++** | Nested dense skip connections | Reduces semantic gap between encoder/decoder |
| **Attention U-Net** | Attention gates on skip connections | Suppresses irrelevant background regions |
| **ResU-Net** | Residual blocks replace plain conv blocks | Deeper training stability |
| **3D U-Net** | 3D conv/pool throughout | Volumetric medical images (CT, MRI) |
| **Swin U-Net** | Transformer attention replaces convolutions | Vision Transformer for segmentation |
| **nnU-Net** | Auto-configures U-Net based on dataset statistics | State-of-the-art medical benchmark baseline |

## Loss Functions for Segmentation

| Loss | Formula (binary) | When to Use |
|---|---|---|
| **Binary Cross-Entropy** | $-[y \log \hat{y} + (1-y)\log(1-\hat{y})]$ | Baseline; struggles with class imbalance |
| **Dice Loss** | $1 - \frac{2 \cdot TP}{2TP + FP + FN}$ | Handles imbalance; common default |
| **BCE + Dice** | weighted sum of both | Most common practical combination |
| **Focal Loss** | Down-weights easy negatives | Severe class imbalance |
| **Tversky Loss** | Generalized Dice with FP/FN weights | When FN more costly than FP |

> [!TIP] Default choice
> **BCE + Dice** loss works well as a starting point for most segmentation tasks.

## Original Paper Tricks

- **Overlap-tile strategy** — for images larger than the input size, predict with overlapping tiles and stitch
- **Elastic deformation** augmentation — key for small datasets (original biomedical use case)
- **Weight map** — adds extra loss weight on borders between touching cells to improve instance separation
- **Mirrored padding** — pads borders with reflected image content instead of zeros

## Minimal PyTorch Sketch

```python
import torch.nn as nn

class DoubleConv(nn.Module):
    def __init__(self, in_ch, out_ch):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv2d(in_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(),
            nn.Conv2d(out_ch, out_ch, 3, padding=1), nn.BatchNorm2d(out_ch), nn.ReLU(),
        )
    def forward(self, x): return self.net(x)

class UNet(nn.Module):
    def __init__(self, in_ch=1, num_classes=2, features=[64, 128, 256, 512]):
        super().__init__()
        self.encoders = nn.ModuleList([DoubleConv(in_ch if i==0 else features[i-1], f) for i, f in enumerate(features)])
        self.pool = nn.MaxPool2d(2)
        self.bottleneck = DoubleConv(features[-1], features[-1]*2)
        self.upconvs = nn.ModuleList([nn.ConvTranspose2d(features[-1]*2//(2**i), features[-1]//(2**i), 2, 2) for i in range(len(features))])
        self.decoders = nn.ModuleList([DoubleConv(features[-1]//(2**i)*2, features[-1]//(2**i)) for i in range(len(features))])  # skip concat doubles ch
        self.head = nn.Conv2d(features[0], num_classes, 1)
    # forward: encode → bottleneck → decode with skip concat → head
```

> [!INFO] Production use
> For serious work, use **nnU-Net** (`pip install nnunetv2`) which auto-configures architecture, preprocessing, and training from dataset properties.

## Related Concepts
- [[13_Deep_Learning_CV_MOC]] - Parent category
- [[13.02 VGG]] - Predecessor CNN architecture; U-Net encoder resembles VGG-style blocks
- [[13.03 Batch Normalization]] - Added in modern U-Net variants for training stability
- [[13.01 Vanishing Gradient]] - Skip connections help gradient flow in deep U-Nets
- [[13.04 EfficientNet]] - Often used as U-Net encoder backbone (U-Net + EfficientNet encoder)
