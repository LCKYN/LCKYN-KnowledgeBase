---
id: 31.03
tags: [type/concept, status/evergreen, context/ai, context/python]
---

# Lazy Loading

## Overview
**Lazy loading** (lazy evaluation) is a design pattern that **defers initialization or computation until the moment it is actually needed**. Instead of loading everything upfront (eager loading), resources are loaded on-demand — saving memory, reducing startup time, and avoiding unnecessary work.

## Lazy vs Eager Loading

| Aspect | Eager Loading | Lazy Loading |
|---|---|---|
| When loaded | Immediately at init | On first access/use |
| Memory usage | High (all upfront) | Low (only what's needed) |
| Startup time | Slow | Fast |
| First-access latency | None (pre-loaded) | Slight delay on first use |
| Wasted work | May load unused data | Only loads what's used |

## Lazy Loading Across Domains

### Data Engineering / ML

| Tool | Lazy Mechanism | How |
|---|---|---|
| **Polars** | Lazy frames | `pl.scan_csv()` → `.collect()` — builds query plan, executes on collect |
| **Spark** | Transformations | All transforms are lazy; only actions (`collect`, `show`) trigger execution |
| **Dask** | Delayed computation | `dask.dataframe.read_csv()` → `.compute()` |
| **Pandas 2.0** | Copy-on-write | `pd.read_csv(..., dtype_backend="pyarrow")` for arrow-backed lazy copies |
| **PyTorch DataLoader** | Batched loading | Loads batches on-demand during training, not entire dataset |
| **HuggingFace Datasets** | Memory-mapped | `load_dataset()` uses Arrow memory-mapping, loads rows on access |

> [!TIP] Polars lazy is the default choice
> For data pipelines, prefer `pl.scan_csv()` / `pl.scan_parquet()` over eager `pl.read_*()`. The query optimizer can push down filters and projections, dramatically reducing I/O.

### Python Modules

```python
# Eager — imported at module load time
import heavy_library

# Lazy — imported only when function is called
def process():
    import heavy_library  # loaded on first call
    return heavy_library.run()
```

### Web / API

| Pattern | Example |
|---|---|
| **Lazy image loading** | `<img loading="lazy">` — browser loads images as they scroll into view |
| **Pagination** | Load 20 items per page instead of entire dataset |
| **Database cursors** | Fetch rows in chunks instead of full result set |
| **Lazy API fields** | GraphQL — client requests only the fields it needs |

### ORM / Database

```python
# SQLAlchemy — lazy load related objects
class User(Base):
    posts = relationship("Post", lazy="select")  # loads on access

# Eager alternative (N+1 prevention)
session.query(User).options(joinedload(User.posts))
```

## When to Use Lazy Loading

| ✅ Use Lazy When | ❌ Use Eager When |
|---|---|
| Dataset doesn't fit in memory | Data is small and always needed |
| Only a subset of data is used | Latency on first access is unacceptable |
| Startup time matters | All items will be accessed anyway |
| Expensive resources may not be needed | Predictable, consistent performance required |

## Common Patterns

| Pattern | Description |
|---|---|
| **Query plan optimization** | Build a DAG of operations, execute only on terminal action (Spark, Polars) |
| **Generator / Iterator** | `yield` one item at a time instead of building full list |
| **Proxy object** | Placeholder that triggers real load on attribute access |
| **Memory-mapped files** | OS pages data in/out of RAM on access (Arrow, numpy memmap) |
| **Virtual scrolling** | UI renders only visible rows (Data Wrangler, ag-Grid) |

> [!WARNING] Watch for N+1 queries
> In ORMs, lazy loading can cause N+1 query problems — one query per related object. Profile and use **eager joins** when you know you'll need all related data.

## Related Concepts
- [[31_System_Design_MOC]] - Parent category
- [[31.02 Serving Architecture]] - Lazy loading in API response design
- [[75.09 Data Wrangler]] - Uses virtual scrolling for large datasets
